# version: '3.8'  # Version is obsolete, Docker Compose v2 handles this automatically

services:
  postgres:
    image: timescale/timescaledb:latest-pg15
    environment:
      POSTGRES_DB: loom
      POSTGRES_USER: loom
      POSTGRES_PASSWORD: loom
      TIMESCALEDB_TELEMETRY: 'off'
      # Fix authentication for external connections
      POSTGRES_HOST_AUTH_METHOD: md5
      # Ensure PostgreSQL listens on all addresses
      POSTGRES_INITDB_ARGS: "--auth-host=md5 --auth-local=trust"
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "5432:5432"
    volumes:
      - ~/.loom/timescaledb:/var/lib/postgresql/data
      - ./services/ingestion-api/migrations:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U loom -d loom"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: |
      postgres
      -c listen_addresses='*'
      -c max_connections=200
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_NUM_PARTITIONS: 3
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    volumes:
      - ~/.loom/kafka/data:/var/lib/kafka/data
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    volumes:
      - ~/.loom/zookeeper/data:/var/lib/zookeeper/data
      - ~/.loom/zookeeper/logs:/var/lib/zookeeper/log

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8081:8080"
    depends_on:
      - kafka

  ingestion-api:
    build:
      context: ./services/ingestion-api
      dockerfile: Dockerfile
    environment:
      LOOM_DATABASE_URL: postgresql://loom:loom@postgres:5432/loom
      LOOM_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOOM_HOST: 0.0.0.0
      LOOM_PORT: 8000
      LOOM_LOG_LEVEL: INFO
      LOOM_ENVIRONMENT: development
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5

  silero-vad:
    build:
      context: ./services/silero-vad
      dockerfile: Dockerfile
    environment:
      LOOM_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOOM_KAFKA_INPUT_TOPIC: device.audio.raw
      LOOM_KAFKA_OUTPUT_TOPIC: media.audio.vad_filtered
      LOOM_VAD_THRESHOLD: "0.5"
      LOOM_LOG_LEVEL: INFO
      LOOM_HOST: 0.0.0.0
      LOOM_PORT: 8001
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8001:8001"
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; r = httpx.get('http://localhost:8001/healthz'); r.raise_for_status()"]
      interval: 10s
      timeout: 5s
      retries: 5

  scheduled-consumers:
    build:
      context: ./services/scheduled-consumers
      dockerfile: Dockerfile
    environment:
      LOOM_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOOM_LOG_LEVEL: INFO
      LOOM_DEVICE_ID: local-dev-scheduled-consumers
      LOOM_EMAIL_CHECK_INTERVAL_MINUTES: 30
      LOOM_SOCIAL_MEDIA_CHECK_INTERVAL_MINUTES: 60
      LOOM_WEB_ACTIVITY_CHECK_INTERVAL_MINUTES: 15
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3

  kyutai-stt:
    build:
      context: ./services/kyutai-stt
      dockerfile: Dockerfile
    environment:
      LOOM_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOOM_KAFKA_INPUT_TOPIC: media.audio.vad_filtered
      LOOM_KAFKA_OUTPUT_TOPIC: media.text.transcribed.words
      LOOM_MODEL_DEVICE: cpu  # Use 'cuda' for GPU support
      LOOM_LOG_LEVEL: INFO
      LOOM_HOST: 0.0.0.0
      LOOM_PORT: 8002
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8002:8002"
    depends_on:
      kafka:
        condition: service_healthy
      silero-vad:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s  # Allow time for model download

  minicpm-vision:
    build:
      context: ./services/minicpm-vision
      dockerfile: Dockerfile
    environment:
      LOOM_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOOM_KAFKA_INPUT_TOPICS: '["device.image.camera.raw", "device.video.screen.raw"]'
      LOOM_KAFKA_OUTPUT_TOPIC: media.image.analysis.minicpm_results
      LOOM_MODEL_DEVICE: cpu  # Use 'cuda' for GPU support
      LOOM_LOG_LEVEL: INFO
      LOOM_HOST: 0.0.0.0
      LOOM_PORT: 8000
      # Disable outlines cache to avoid permission issues
      OUTLINES_CACHE_DIR: /tmp/outlines_cache
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8003:8000"
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ~/.loom/models:/home/loom/.cache  # Model cache directory
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s  # Allow time for model download
    deploy:
      resources:
        limits:
          memory: 8G  # MiniCPM-V requires significant memory
        reservations:
          memory: 4G

  pipeline-monitor-api:
    build:
      context: ./services/pipeline-monitor-api
      dockerfile: Dockerfile
    environment:
      PORT: 8080
      LOOM_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOOM_DATABASE_HOST: postgres
      LOOM_DATABASE_PORT: 5432
      LOOM_DATABASE_NAME: loom
      LOOM_DATABASE_USER: loom
      LOOM_DATABASE_PASSWORD: loom
      CORS_ORIGIN: http://localhost:3000
      LOG_LEVEL: info
      NODE_ENV: development
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8082:8080"
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:8080/health/live', (res) => { process.exit(res.statusCode === 200 ? 0 : 1) }).on('error', () => process.exit(1))"]
      interval: 30s
      timeout: 5s
      retries: 5

  pipeline-monitor:
    build:
      context: ./services/pipeline-monitor
      dockerfile: Dockerfile
    environment:
      VITE_API_URL: http://localhost:8082
      VITE_TEST_PRODUCER_URL: http://localhost:8008
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "3000:3000"
    depends_on:
      - pipeline-monitor-api
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Data Fetcher Services
  hackernews-fetcher:
    build:
      context: ./services/hackernews-fetcher
      dockerfile: Dockerfile
    environment:
      # Kafka configuration (fetchers use KAFKA_BOOTSTRAP_SERVERS not LOOM_KAFKA_BOOTSTRAP_SERVERS)
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC_PREFIX: ""  # No prefix, use full topic names
      LOOM_KAFKA_OUTPUT_TOPIC: external.hackernews.favorites.raw
      LOOM_DEVICE_ID: local-dev-hackernews-fetcher
      LOOM_LOG_LEVEL: INFO
      LOOM_FETCH_INTERVAL_MINUTES: 15
      # HackerNews credentials from .env file
      LOOM_HACKERNEWS_USERNAME: ${LOOM_HACKERNEWS_USERNAME:-}
      LOOM_HACKERNEWS_PASSWORD: ${LOOM_HACKERNEWS_PASSWORD:-}
      LOOM_HACKERNEWS_MAX_ITEMS: ${LOOM_HACKERNEWS_MAX_ITEMS:-100}
      LOOM_HACKERNEWS_FETCH_TYPE: ${LOOM_HACKERNEWS_FETCH_TYPE:-favorites}
      LOOM_HACKERNEWS_USE_BROWSER: ${LOOM_HACKERNEWS_USE_BROWSER:-false}
      LOOM_HACKERNEWS_RATE_LIMIT_SECONDS: ${LOOM_HACKERNEWS_RATE_LIMIT_SECONDS:-0.5}
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    volumes:
      - ~/.loom/logs/hackernews:/app/logs
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  gmail-fetcher:
    build:
      context: ./services/email-fetcher
      dockerfile: Dockerfile
    environment:
      # Kafka configuration (fetchers use KAFKA_BOOTSTRAP_SERVERS not LOOM_KAFKA_BOOTSTRAP_SERVERS)
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC_PREFIX: ""  # No prefix, use full topic names
      LOOM_KAFKA_OUTPUT_TOPIC: external.email.events.raw
      LOOM_DEVICE_ID: ${LOOM_DEVICE_ID_GMAIL:-local-dev-gmail-fetcher}
      LOOM_LOG_LEVEL: ${LOOM_LOG_LEVEL:-INFO}
      LOOM_FETCH_INTERVAL_MINUTES: ${LOOM_FETCH_INTERVAL_MINUTES_GMAIL:-5}
      # Gmail configuration from .env file
      LOOM_EMAIL_ADDRESS_1: ${LOOM_EMAIL_1:-}
      LOOM_EMAIL_PASSWORD_1: ${LOOM_EMAIL_PASSWORD_1:-}
      LOOM_EMAIL_IMAP_SERVER_1: ${LOOM_EMAIL_IMAP_SERVER_1:-imap.gmail.com}
      LOOM_EMAIL_IMAP_PORT_1: ${LOOM_EMAIL_PORT_1:-993}
      LOOM_EMAIL_NAME_1: ${LOOM_EMAIL_NAME_1:-Gmail}
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  fastmail-fetcher:
    build:
      context: ./services/email-fetcher
      dockerfile: Dockerfile
    environment:
      # Kafka configuration (fetchers use KAFKA_BOOTSTRAP_SERVERS not LOOM_KAFKA_BOOTSTRAP_SERVERS)
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC_PREFIX: ""  # No prefix, use full topic names
      LOOM_KAFKA_OUTPUT_TOPIC: external.email.events.raw
      LOOM_DEVICE_ID: ${LOOM_DEVICE_ID_FASTMAIL:-local-dev-fastmail-fetcher}
      LOOM_LOG_LEVEL: ${LOOM_LOG_LEVEL:-INFO}
      LOOM_FETCH_INTERVAL_MINUTES: ${LOOM_FETCH_INTERVAL_MINUTES_FASTMAIL:-5}
      # Fastmail configuration from .env file (as account 1 for this fetcher)
      LOOM_EMAIL_ADDRESS_1: ${LOOM_EMAIL_2:-}
      LOOM_EMAIL_PASSWORD_1: ${LOOM_EMAIL_PASSWORD_2:-}
      LOOM_EMAIL_IMAP_SERVER_1: ${LOOM_EMAIL_IMAP_SERVER_2:-imap.fastmail.com}
      LOOM_EMAIL_IMAP_PORT_1: ${LOOM_EMAIL_PORT_2:-993}
      LOOM_EMAIL_NAME_1: ${LOOM_EMAIL_NAME_2:-Fastmail}
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  calendar-fetcher:
    build:
      context: ./services/calendar-fetcher
      dockerfile: Dockerfile
    environment:
      # Kafka configuration (fetchers use KAFKA_BOOTSTRAP_SERVERS not LOOM_KAFKA_BOOTSTRAP_SERVERS)
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC_PREFIX: ""  # No prefix, use full topic names
      LOOM_KAFKA_OUTPUT_TOPIC: ${LOOM_KAFKA_OUTPUT_TOPIC_CALENDAR:-external.calendar.events.raw}
      LOOM_DEVICE_ID: ${LOOM_DEVICE_ID_CALENDAR:-local-dev-calendar-fetcher}
      LOOM_LOG_LEVEL: ${LOOM_LOG_LEVEL:-INFO}
      LOOM_FETCH_INTERVAL_MINUTES: ${LOOM_FETCH_INTERVAL_MINUTES_CALENDAR:-10}
      # CalDAV configuration from .env file
      LOOM_CALDAV_URL_1: ${LOOM_CALDAV_URL_1:-}
      LOOM_CALDAV_USERNAME_1: ${LOOM_CALDAV_USERNAME_1:-}
      LOOM_CALDAV_PASSWORD_1: ${LOOM_CALDAV_PASSWORD_1:-}
      LOOM_CALDAV_NAME_1: ${LOOM_CALDAV_NAME_1:-}
      LOOM_CALDAV_DISABLED_1: ${LOOM_CALDAV_DISABLED_1:-false}
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  x-likes-fetcher:
    build:
      context: ./services/x-likes-fetcher
      dockerfile: Dockerfile
    environment:
      # Kafka configuration (fetchers use KAFKA_BOOTSTRAP_SERVERS not LOOM_KAFKA_BOOTSTRAP_SERVERS)
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC_PREFIX: ""  # No prefix, use full topic names
      LOOM_KAFKA_OUTPUT_TOPIC: ${LOOM_KAFKA_OUTPUT_TOPIC_X:-external.twitter.liked.raw}
      LOOM_KAFKA_URL_TOPIC: ${LOOM_KAFKA_URL_TOPIC_X:-task.url.ingest}
      LOOM_SEND_TO_URL_PROCESSOR: ${LOOM_SEND_TO_URL_PROCESSOR_X:-true}
      LOOM_DEVICE_ID: local-dev-x-likes-fetcher
      LOOM_LOG_LEVEL: INFO
      LOOM_FETCH_INTERVAL_HOURS: ${LOOM_FETCH_INTERVAL_HOURS_X:-6}
      LOOM_RUN_ON_STARTUP: ${LOOM_RUN_ON_STARTUP_X:-true}
      LOOM_MAX_TWEETS_TO_FETCH: 1000  # Fetch up to 1000 tweets
      LOOM_MAX_FETCH_TIME_MINUTES: 120  # Stop after 2 hours
      # Database configuration for duplicate checking
      LOOM_DATABASE_URL: postgresql://loom:loom@postgres:5432/loom
      # X/Twitter authentication (from .env file)
      LOOM_X_USERNAME: ${X_USERNAME:-}
      LOOM_X_PASSWORD: ${X_PASSWORD:-}
      LOOM_X_PHONE_NUMBER: ${X_PHONE_NUMBER:-}
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    volumes:
      - ~/.loom/x-likes-sessions:/app/sessions
      - ~/.loom/logs/x-likes:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Processing Services
  hackernews-url-processor:
    build:
      context: ./services/hackernews-url-processor
      dockerfile: Dockerfile
    environment:
      # Kafka configuration
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC_PREFIX: ""  # No prefix, use full topic names
      LOOM_KAFKA_INPUT_TOPIC: external.hackernews.favorites.raw
      LOOM_KAFKA_OUTPUT_TOPIC: task.url.processed.hackernews_archived
      LOOM_LOG_LEVEL: INFO
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    volumes:
      - ~/.loom/logs/hackernews-processor:/app/logs
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  x-url-processor:
    build:
      context: ./services/x-url-processor
      dockerfile: Dockerfile
    environment:
      # Kafka configuration
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC_PREFIX: ""  # No prefix, use full topic names
      LOOM_KAFKA_INPUT_TOPIC: external.twitter.liked.raw  # Only process from Twitter liked topic
      LOOM_KAFKA_OUTPUT_TOPIC: task.url.processed.twitter_archived
      LOOM_LOG_LEVEL: INFO
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    volumes:
      - ~/.loom/twitter_images:/app/screenshots
      - ~/.loom/logs/x-url-processor:/app/logs
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Database Consumer (Legacy)
  kafka-to-db-consumer:
    build:
      context: ./services/kafka-to-db-consumer
      dockerfile: Dockerfile
    environment:
      LOOM_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOOM_DATABASE_URL: postgresql://loom:loom@postgres:5432/loom
      LOOM_LOG_LEVEL: INFO
      CONSUMER_TYPE: legacy  # Use legacy consumer
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    volumes:
      - ~/.loom/logs/kafka-to-db:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Generic Database Consumer (New mapping-based)
  generic-kafka-to-db-consumer:
    build:
      context: ./services/kafka-to-db-consumer
      dockerfile: Dockerfile
    environment:
      LOOM_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOOM_DATABASE_URL: postgresql://loom:loom@postgres:5432/loom
      LOOM_LOG_LEVEL: INFO
      CONSUMER_TYPE: generic  # Use new generic consumer
      KAFKA_GROUP_ID: generic-kafka-to-db-consumer
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8009:8001"  # Different port to avoid conflict
    volumes:
      - ~/.loom/logs/generic-kafka-to-db:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Text Embedder Service
  text-embedder:
    build:
      context: ./services/text-embedder
      dockerfile: Dockerfile
    environment:
      LOOM_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOOM_DATABASE_URL: postgresql://loom:loom@postgres:5432/loom
      LOOM_KAFKA_EMAIL_TOPIC: external.email.events.raw
      LOOM_KAFKA_TWITTER_TOPIC: external.twitter.liked.raw
      LOOM_KAFKA_EMBEDDED_EMAIL_TOPIC: analysis.text.embedded.emails
      LOOM_KAFKA_EMBEDDED_TWITTER_TOPIC: analysis.text.embedded.twitter
      LOOM_EMBEDDING_MODEL: sentence-transformers/all-MiniLM-L6-v2
      LOOM_DEVICE: cpu
      LOOM_LOG_LEVEL: INFO
      LOOM_HOST: 0.0.0.0
      LOOM_PORT: 8006
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8006:8006"
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ~/.loom/models:/models  # Model cache directory
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; r = httpx.get('http://localhost:8006/healthz'); r.raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s  # Allow time for model download
    restart: unless-stopped

  # Additional AI Services
  bud-e-emotion:
    build:
      context: ./services/bud-e-emotion
      dockerfile: Dockerfile
    environment:
      LOOM_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOOM_KAFKA_INPUT_TOPIC: media.audio.vad_filtered
      LOOM_KAFKA_OUTPUT_TOPIC: analysis.audio.emotion_results
      LOOM_MODEL_DEVICE: cpu  # Use 'cuda' for GPU support
      LOOM_LOG_LEVEL: INFO
      LOOM_HOST: 0.0.0.0
      LOOM_PORT: 8004
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8004:8004"
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ~/.loom/models:/home/loom/.cache  # Model cache directory
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8004/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s  # Allow time for model download
    restart: unless-stopped

  face-emotion:
    build:
      context: ./services/face-emotion
      dockerfile: Dockerfile
    environment:
      LOOM_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOOM_KAFKA_INPUT_TOPIC: media.image.analysis.minicpm_results
      LOOM_KAFKA_OUTPUT_TOPIC: analysis.image.emotion_results
      LOOM_MODEL_DEVICE: cpu  # Use 'cuda' for GPU support
      LOOM_LOG_LEVEL: INFO
      LOOM_HOST: 0.0.0.0
      LOOM_PORT: 8005
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8005:8005"
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ~/.loom/models:/home/loom/.cache  # Model cache directory
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8005/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s  # Allow time for model download
    restart: unless-stopped

  moondream-ocr:
    build:
      context: ./services/moondream-ocr
      dockerfile: Dockerfile
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      PORT: 8007
      MOONDREAM_MODEL_CACHE: /home/aoi/.loom/moondream
      HF_HOME: /home/aoi/.loom/moondream
      TORCH_HOME: /home/aoi/.loom/moondream
      TRANSFORMERS_CACHE: /home/aoi/.loom/moondream
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8007:8007"
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ~/.loom:/home/aoi/.loom  # Model cache directory
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8007/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s  # Allow time for model download
    deploy:
      resources:
        limits:
          memory: 8G  # Moondream requires significant memory
        reservations:
          memory: 4G
    restart: unless-stopped

  twitter-ocr-processor:
    build:
      context: ./services/twitter-ocr-processor
      dockerfile: Dockerfile
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      DATABASE_URL: postgresql://loom:loom@postgres:5432/loom
      MOONDREAM_OCR_URL: http://moondream-ocr:8007
      LOG_LEVEL: INFO
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      moondream-ocr:
        condition: service_started
    restart: unless-stopped

  kafka-test-producer:
    build:
      context: ./services/kafka-test-producer
      dockerfile: Dockerfile
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      LOG_LEVEL: INFO
      # Set timezone
      TZ: UTC
      DEBIAN_FRONTEND: noninteractive
    ports:
      - "8008:8008"
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8008/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # onefilellm:  # Temporarily disabled due to GitHub access issues
  #   build:
  #     context: ./services/onefilellm
  #     dockerfile: Dockerfile
  #   environment:
  #     KAFKA_BOOTSTRAP_SERVERS: kafka:29092
  #     DATABASE_URL: postgresql://loom:loom@postgres:5432/loom
  #     TOPIC_GITHUB_INGEST: task.github.ingest
  #     TOPIC_DOCUMENT_INGEST: task.document.ingest
  #     TOPIC_GITHUB_PARSED: processed.github.parsed
  #     TOPIC_DOCUMENT_PARSED: processed.document.parsed
  #     LOG_LEVEL: INFO
  #     HOST: 0.0.0.0
  #     PORT: 8080
  #     MAX_FILE_SIZE_MB: 100
  #     MAX_REPO_FILES: 1000
  #     GITHUB_CLONE_TIMEOUT: 300
  #     PROCESSING_TIMEOUT: 600
  #   ports:
  #     - "8080:8080"
  #   depends_on:
  #     postgres:
  #       condition: service_healthy
  #     kafka:
  #       condition: service_healthy
  #   volumes:
  #     - ./temp_repos:/tmp/repos  # Temporary directory for cloning repos
  #   healthcheck:
  #     test: ["CMD", "python", "-c", "import httpx; r = httpx.get('http://localhost:8080/health'); r.raise_for_status()"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 60s  # Allow time for OneFileLLM setup
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 4G  # OneFileLLM can be memory intensive
  #       reservations:
  #         memory: 2G

# volumes:
#   postgres_data: # Now using host directory ~/.loom/timescaledb

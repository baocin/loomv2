# Loom v2 Development Environment Configuration
# Copy this file to .env and fill in your credentials

# =============================================================================
# Core Infrastructure Configuration
# =============================================================================
# PostgreSQL/TimescaleDB Configuration
POSTGRES_DB=loom
POSTGRES_USER=loom
POSTGRES_PASSWORD=loom
LOOM_DATABASE_URL=postgresql://loom:loom@postgres:5432/loom

# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
LOOM_KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC_PREFIX=""

# Global Configuration
LOG_LEVEL=INFO
LOOM_LOG_LEVEL=INFO
ENVIRONMENT=development
LOOM_ENVIRONMENT=development
TZ=UTC

# =============================================================================
# Ingestion API Configuration
# =============================================================================
LOOM_HOST=0.0.0.0
LOOM_PORT=8000
LOOM_CORS_ORIGINS=*

# =============================================================================
# AI Model Services Configuration
# =============================================================================

# Silero VAD (Voice Activity Detection)
LOOM_VAD_THRESHOLD=0.5
# Kafka topics for VAD service
LOOM_KAFKA_INPUT_TOPIC_VAD=device.audio.raw
LOOM_KAFKA_OUTPUT_TOPIC_VAD=media.audio.vad_filtered

# Parakeet TDT (Speech-to-Text)
LOOM_MODEL_DEVICE_PARAKEET=cpu  # Use 'cuda' for GPU support
# Kafka topics for Parakeet service
LOOM_KAFKA_INPUT_TOPIC_PARAKEET=media.audio.vad_filtered
LOOM_KAFKA_OUTPUT_TOPIC_PARAKEET=media.text.transcribed.words

# MiniCPM Vision (Vision-Language Model)
LOOM_MODEL_DEVICE_MINICPM=cpu  # Use 'cuda' for GPU support
# Kafka topics for MiniCPM service (JSON array format)
LOOM_KAFKA_INPUT_TOPICS_MINICPM=["device.image.camera.raw", "device.video.screen.raw"]
LOOM_KAFKA_OUTPUT_TOPIC_MINICPM=media.image.analysis.minicpm_results

# BUD-E Emotion (Audio Emotion Recognition)
LOOM_MODEL_DEVICE_BUDE=cpu  # Use 'cuda' for GPU support
# Kafka topics for BUD-E service
LOOM_KAFKA_INPUT_TOPIC_BUDE=media.audio.vad_filtered
LOOM_KAFKA_OUTPUT_TOPIC_BUDE=analysis.audio.emotion_results

# Face Emotion (Image Emotion Recognition)
LOOM_MODEL_DEVICE_FACE=cpu  # Use 'cuda' for GPU support
# Kafka topics for Face Emotion service
LOOM_KAFKA_INPUT_TOPIC_FACE=media.image.analysis.minicpm_results
LOOM_KAFKA_OUTPUT_TOPIC_FACE=analysis.image.emotion_results

# =============================================================================
# Data Fetcher Services Configuration
# =============================================================================

# X/Twitter Fetcher Configuration (Required for X likes fetching)
X_USERNAME=your-twitter-username
X_PASSWORD=your-twitter-password
# Phone number may be required for some accounts (include country code)
X_PHONE_NUMBER=+1234567890
LOOM_KAFKA_OUTPUT_TOPIC_X=external.twitter.liked.raw
LOOM_FETCH_INTERVAL_MINUTES_X=30

# Gmail Fetcher Configuration (First email container)
GMAIL_IMAP_SERVER=imap.gmail.com
GMAIL_IMAP_PORT=993
GMAIL_USERNAME=your-email@gmail.com
GMAIL_PASSWORD=your-gmail-app-password
LOOM_KAFKA_OUTPUT_TOPIC_GMAIL=external.email.gmail.raw
LOOM_FETCH_INTERVAL_MINUTES_GMAIL=5
LOOM_DEVICE_ID_GMAIL=local-dev-gmail-fetcher

# Fastmail Fetcher Configuration (Second email container)
FASTMAIL_IMAP_SERVER=imap.fastmail.com
FASTMAIL_IMAP_PORT=993
FASTMAIL_USERNAME=your-email@fastmail.com
FASTMAIL_PASSWORD=your-fastmail-app-password
LOOM_KAFKA_OUTPUT_TOPIC_FASTMAIL=external.email.fastmail.raw
LOOM_FETCH_INTERVAL_MINUTES_FASTMAIL=5
LOOM_DEVICE_ID_FASTMAIL=local-dev-fastmail-fetcher

# Alternative email providers for additional containers:
# Outlook: IMAP_SERVER=outlook.office365.com
# Yahoo: IMAP_SERVER=imap.mail.yahoo.com
# ProtonMail Bridge: IMAP_SERVER=127.0.0.1, IMAP_PORT=1143
# Custom: IMAP_SERVER=your-custom-imap-server.com

# Calendar Fetcher Configuration (Required for calendar fetching)
# Google Calendar OAuth2 credentials
# 1. Go to https://console.cloud.google.com/
# 2. Create a new project or select existing
# 3. Enable Google Calendar API
# 4. Create OAuth2 credentials (Desktop application type)
# 5. Use the OAuth2 flow to get a refresh token
GOOGLE_CALENDAR_CLIENT_ID=your-google-client-id.apps.googleusercontent.com
GOOGLE_CALENDAR_CLIENT_SECRET=your-google-client-secret
GOOGLE_CALENDAR_REFRESH_TOKEN=your-google-refresh-token
# Alternative: Service account credentials as JSON string (for server apps)
# GOOGLE_CALENDAR_CREDENTIALS_JSON={"type":"service_account","project_id":"...","private_key":"...","client_email":"..."}

# Microsoft Outlook Calendar credentials
# 1. Go to https://portal.azure.com/
# 2. Register a new application in Azure AD
# 3. Add Calendar.Read permission
# 4. Create a client secret
# 5. Use OAuth2 flow to get refresh token
OUTLOOK_CLIENT_ID=your-outlook-client-id
OUTLOOK_CLIENT_SECRET=your-outlook-client-secret
OUTLOOK_REFRESH_TOKEN=your-outlook-refresh-token

# Calendar service configuration
LOOM_KAFKA_OUTPUT_TOPIC_CALENDAR=external.calendar.events.raw
LOOM_FETCH_INTERVAL_MINUTES_CALENDAR=10
LOOM_DEVICE_ID_CALENDAR=local-dev-calendar-fetcher

# HackerNews Fetcher Configuration (Optional)
HACKERNEWS_USERNAME=your-hackernews-username
LOOM_KAFKA_OUTPUT_TOPIC_HACKERNEWS=external.hackernews.favorites.raw
LOOM_FETCH_INTERVAL_MINUTES_HACKERNEWS=15

# =============================================================================
# Processing Services Configuration
# =============================================================================

# HackerNews URL Processor
LOOM_KAFKA_INPUT_TOPIC_HACKERNEWS_PROCESSOR=external.hackernews.favorites.raw
LOOM_KAFKA_OUTPUT_TOPIC_HACKERNEWS_PROCESSOR=processed.hackernews.content

# X URL Processor
LOOM_KAFKA_INPUT_TOPIC_X_PROCESSOR=external.twitter.liked.raw
LOOM_KAFKA_OUTPUT_TOPIC_X_PROCESSOR=processed.twitter.content

# Kafka to Database Consumer
LOOM_KAFKA_CONSUMER_TOPICS=["device.audio.raw", "device.sensor.gps.raw", "device.sensor.accelerometer.raw", "media.text.transcribed.words", "analysis.audio.emotion_results", "analysis.image.emotion_results", "external.email.gmail.raw", "external.email.fastmail.raw", "external.calendar.events.raw", "external.twitter.liked.raw", "external.hackernews.favorites.raw"]

# =============================================================================
# Scheduled Consumers Configuration
# =============================================================================
LOOM_DEVICE_ID_SCHEDULED=local-dev-scheduled-consumers
LOOM_EMAIL_CHECK_INTERVAL_MINUTES=30
LOOM_SOCIAL_MEDIA_CHECK_INTERVAL_MINUTES=60
LOOM_WEB_ACTIVITY_CHECK_INTERVAL_MINUTES=15

# =============================================================================
# Pipeline Monitor Configuration
# =============================================================================
PORT_MONITOR_API=8080
LOOM_DATABASE_HOST=postgres
LOOM_DATABASE_PORT=5432
LOOM_DATABASE_NAME=loom
LOOM_DATABASE_USER=loom
LOOM_DATABASE_PASSWORD=loom
CORS_ORIGIN=http://localhost:3000
NODE_ENV=development

# Pipeline Monitor Frontend
VITE_API_URL=http://localhost:8082

# =============================================================================
# Service Ports Configuration
# =============================================================================
# Main services
PORT_INGESTION_API=8000
PORT_PIPELINE_MONITOR_API=8082
PORT_PIPELINE_MONITOR=3000
PORT_KAFKA_UI=8081
PORT_POSTGRES=5432
PORT_KAFKA=9092

# AI service ports
PORT_SILERO_VAD=8001
PORT_PARAKEET_TDT=8002
PORT_MINICPM_VISION=8003
PORT_BUD_E_EMOTION=8004
PORT_FACE_EMOTION=8005

# =============================================================================
# Device IDs for Services
# =============================================================================
LOOM_DEVICE_ID_HACKERNEWS=local-dev-hackernews-fetcher
LOOM_DEVICE_ID_CALENDAR=local-dev-calendar-fetcher
LOOM_DEVICE_ID_X=local-dev-x-likes-fetcher
# Note: Gmail and Fastmail device IDs are defined in their respective sections above

# =============================================================================
# Model Configuration & Optimization
# =============================================================================
# Model cache directory (shared across AI services)
MODEL_CACHE_DIR=./models

# GPU/CPU device selection for AI models
# Options: cpu, cuda, auto
AI_DEVICE_PREFERENCE=cpu

# Memory limits for AI services (Docker deploy resources)
MEMORY_LIMIT_MINICPM=8G
MEMORY_RESERVATION_MINICPM=4G
MEMORY_LIMIT_ONEFILELLM=4G
MEMORY_RESERVATION_ONEFILELLM=2G

# =============================================================================
# OneFileLLM Configuration (Currently disabled)
# =============================================================================
# KAFKA_TOPIC_GITHUB_INGEST=task.github.ingest
# KAFKA_TOPIC_DOCUMENT_INGEST=task.document.ingest
# KAFKA_TOPIC_GITHUB_PARSED=processed.github.parsed
# KAFKA_TOPIC_DOCUMENT_PARSED=processed.document.parsed
# ONEFILELLM_HOST=0.0.0.0
# ONEFILELLM_PORT=8080
# MAX_FILE_SIZE_MB=100
# MAX_REPO_FILES=1000
# GITHUB_CLONE_TIMEOUT=300
# PROCESSING_TIMEOUT=600

# =============================================================================
# Development & Debugging Configuration
# =============================================================================
# Container restart policies
RESTART_POLICY=unless-stopped

# Health check intervals
HEALTHCHECK_INTERVAL=30s
HEALTHCHECK_TIMEOUT=10s
HEALTHCHECK_RETRIES=5
HEALTHCHECK_START_PERIOD=60s

# Debug mode for services
DEBUG_MODE=false
VERBOSE_LOGGING=false

# =============================================================================
# Security & Authentication Configuration
# =============================================================================
# API Keys and tokens (add your own)
# OPENAI_API_KEY=your-openai-api-key
# ANTHROPIC_API_KEY=your-anthropic-api-key
# HUGGINGFACE_TOKEN=your-huggingface-token

# JWT secrets (generate secure random strings)
# JWT_SECRET=your-super-secure-jwt-secret-key
# API_SECRET_KEY=your-super-secure-api-secret-key

# =============================================================================
# External API Configuration
# =============================================================================
# Rate limiting for external APIs
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_BURST=10

# Timeout configurations
HTTP_TIMEOUT_SECONDS=30
KAFKA_TIMEOUT_SECONDS=10
DATABASE_TIMEOUT_SECONDS=30

# =============================================================================
# Monitoring & Observability
# =============================================================================
# Prometheus metrics
ENABLE_METRICS=true
METRICS_PORT=9090

# Jaeger tracing
ENABLE_TRACING=true
JAEGER_ENDPOINT=http://localhost:14268/api/traces

# Structured logging
LOG_FORMAT=json
LOG_OUTPUT=stdout

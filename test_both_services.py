#!/usr/bin/env python3
"""Test script for Gemma 3N and Moondream Station services"""

import sys
from datetime import datetime
import base64
from io import BytesIO
from PIL import Image

# Add service paths
sys.path.insert(0, "services/gemma3n-processor")
sys.path.insert(0, "services/moondream-station")

print("üß™ TESTING LOOM V2 AI SERVICES")
print("=" * 60)

# Test Gemma 3N
print("\nüì¶ GEMMA 3N PROCESSOR")
print("-" * 40)

try:
    sys.path.insert(0, "services/gemma3n-processor")
    from app.models import (
        TextMessage,
        ImageMessage,
        MultimodalRequest,
    )
    from app.config import settings as gemma_settings

    # Create test data
    text_msg = TextMessage(
        device_id="test-device",
        recorded_at=datetime.utcnow(),
        text="Analyze this text for sentiment and key topics",
        context="Customer feedback",
    )
    print(f"‚úì Text Message: '{text_msg.text[:30]}...'")

    # Create multimodal request
    multimodal_req = MultimodalRequest(
        prompt="Analyze all modalities",
        text="Sample text content",
        image_data="base64imagedata",
        max_tokens=2000,
    )
    print(f"‚úì Multimodal Request: {multimodal_req.prompt}")

    # Show configuration
    print("\nConfiguration:")
    print(f"  - Service: {gemma_settings.service_name}")
    print(f"  - Model: {gemma_settings.ollama_model}")
    print(f"  - Max Tokens: {gemma_settings.model_max_tokens}")
    print(f"  - Input Topics: {len(gemma_settings.kafka_input_topics)}")

    print("\n‚úÖ Gemma 3N service components working!")

except Exception as e:
    print(f"‚ùå Gemma 3N Error: {e}")

# Test Moondream Station
print("\n\nüì¶ MOONDREAM STATION")
print("-" * 40)

try:
    sys.path.insert(0, "services/moondream-station")
    from app.models import (
        ImageMessage,
        ImageAnalysisRequest,
        DetectedObject,
    )
    from app.config import settings as moon_settings

    # Create test image
    img = Image.new("RGB", (200, 200), color="blue")
    buffer = BytesIO()
    img.save(buffer, format="PNG")
    img_base64 = base64.b64encode(buffer.getvalue()).decode()

    # Create image message
    img_msg = ImageMessage(
        device_id="camera-001",
        recorded_at=datetime.utcnow(),
        data=img_base64,
        format="png",
        metadata={"location": "test-lab"},
    )
    print(f"‚úì Image Message: device={img_msg.device_id}, format={img_msg.format}")

    # Create analysis request
    analysis_req = ImageAnalysisRequest(
        image_data=img_base64,
        query="What color is this image?",
        enable_object_detection=True,
        enable_ocr=True,
    )
    print(f"‚úì Analysis Request: '{analysis_req.query}'")

    # Create mock object detection
    detected_obj = DetectedObject(
        label="test_object", confidence=0.95, bbox=[10, 10, 100, 100]
    )
    print(f"‚úì Object Detection: {detected_obj.label} (conf={detected_obj.confidence})")

    # Show configuration
    print("\nConfiguration:")
    print(f"  - Service: {moon_settings.service_name}")
    print(f"  - Moondream URL: {moon_settings.moondream_host}")
    print(f"  - Max Image Size: {moon_settings.max_image_size}px")
    print(f"  - Input Topics: {len(moon_settings.kafka_input_topics)}")

    print("\n‚úÖ Moondream Station service components working!")

except Exception as e:
    print(f"‚ùå Moondream Station Error: {e}")

# Summary
print("\n\nüìä SUMMARY")
print("=" * 60)
print("Both services are configured and ready for deployment!")
print("\nKey Features:")
print("- Gemma 3N: Multimodal AI (text, image, audio) via Ollama")
print("- Moondream Station: Vision AI with object detection & OCR")
print("- Kafka Integration: Stream processing for both services")
print("- Docker Ready: Containerized for easy deployment")
print("- Kubernetes Ready: Deployment configs for CPU/GPU nodes")

print("\nüöÄ To deploy:")
print("  1. Build Docker images: make docker")
print("  2. Deploy to K8s: make k8s-deploy")
print("  3. Check status: make k8s-status")
